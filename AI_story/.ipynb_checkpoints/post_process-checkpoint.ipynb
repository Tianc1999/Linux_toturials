{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "import numpy\n",
    "\n",
    "from pathlib import Path\n",
    "import onnxruntime_extensions\n",
    "\n",
    "\n",
    "def get_yolo_model(version: int, onnx_model_name: str):\n",
    "    # install yolov8\n",
    "    from pip._internal import main as pipmain\n",
    "    try:\n",
    "        import ultralytics\n",
    "    except ImportError:\n",
    "        pipmain(['install', 'ultralytics'])\n",
    "        import ultralytics\n",
    "    pt_model = Path(f\"yolov{version}n.pt\")\n",
    "    model = ultralytics.YOLO(str(pt_model))  # load a pretrained model\n",
    "    exported_filename = model.export(format=\"onnx\")  # export the model to ONNX format\n",
    "    assert exported_filename, f\"Failed to export yolov{version}n.pt to onnx\"\n",
    "    import shutil\n",
    "    shutil.move(exported_filename, onnx_model_name)\n",
    "\n",
    "\n",
    "def add_pre_post_processing_to_yolo(input_model_file: Path, output_model_file: Path):\n",
    "    \"\"\"Construct the pipeline for an end2end model with pre and post processing. \n",
    "    The final model can take raw image binary as inputs and output the result in raw image file.\n",
    "\n",
    "    Args:\n",
    "        input_model_file (Path): The onnx yolo model.\n",
    "        output_model_file (Path): where to save the final onnx model.\n",
    "    \"\"\"\n",
    "    from onnxruntime_extensions.tools import add_pre_post_processing_to_model as add_ppp\n",
    "    add_ppp.yolo_detection(input_model_file, output_model_file, \"jpg\", onnx_opset=18)\n",
    "\n",
    "\n",
    "def run_inference(onnx_model_file: Path):\n",
    "    import onnxruntime as ort\n",
    "    import numpy as np\n",
    "\n",
    "    providers = ['CPUExecutionProvider']\n",
    "    session_options = ort.SessionOptions()\n",
    "    session_options.register_custom_ops_library(onnxruntime_extensions.get_library_path())\n",
    "\n",
    "    image = np.frombuffer(open('../test/data/ppp_vision/wolves.jpg', 'rb').read(), dtype=np.uint8)\n",
    "    session = ort.InferenceSession(str(onnx_model_file), providers=providers, sess_options=session_options)\n",
    "\n",
    "    inname = [i.name for i in session.get_inputs()]\n",
    "    inp = {inname[0]: image}\n",
    "    output = session.run(['image_out'], inp)[0]\n",
    "    output_filename = '../test/data/result.jpg'\n",
    "    open(output_filename, 'wb').write(output)\n",
    "    from PIL import Image\n",
    "    Image.open(output_filename).show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # YOLO version. Tested with 5 and 8.\n",
    "    version = 8\n",
    "    onnx_model_name = Path(f\"../test/data/yolov{version}n.onnx\")\n",
    "    if not onnx_model_name.exists():\n",
    "        print(\"Fetching original model...\")\n",
    "        get_yolo_model(version, str(onnx_model_name))\n",
    "\n",
    "    onnx_e2e_model_name = onnx_model_name.with_suffix(suffix=\".with_pre_post_processing.onnx\")\n",
    "    print(\"Adding pre/post processing...\")\n",
    "    add_pre_post_processing_to_yolo(onnx_model_name, onnx_e2e_model_name)\n",
    "    print(\"Testing updated model...\")\n",
    "    run_inference(onnx_e2e_model_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
