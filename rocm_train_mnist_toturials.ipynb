{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda env base ,test ok\n",
    "# ubuntu rocm  * |  windows  dml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d, Linear, ReLU\n",
    "from torch.nn import MaxPool2d\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 预处理：Compose将步骤整合\n",
    "transform = transforms.Compose({\n",
    "    transforms.ToTensor(),  # 将灰度图片像素值（0~255）转为Tensor（0~1），方便后续处理\n",
    "    # transforms.Normalize((0.1307,),(0.3081)),    # 归一化，均值0，方差1;mean:各通道的均值std：各通道的标准差inplace：是否原地操作\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度：60000\n",
      "测试数据集的长度：10000\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集和训练数据集\n",
    "train_data = MNIST(root='./mnist/data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# 测试数据集\n",
    "test_data = MNIST(root=\"./mnist/data\", train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride=1, padding=0)\n",
    "        self.maxpool2 = MaxPool2d(2)\n",
    "        self.linear1 = Linear(320, 128)\n",
    "        self.linear2 = Linear(128, 64)\n",
    "        self.linear3 = Linear(64, 10)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.maxpool1(self.conv1(x)))\n",
    "        x = self.relu(self.maxpool2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 损失函数CrossentropyLoss\n",
    "model = MnistModel()#实例化\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # 交叉熵损失，相当于Softmax+Log+NllLoss\n",
    "# 线性多分类模型Softmax,给出最终预测值对于10个类别出现的概率，Log:将乘法转换为加法，减少计算量，保证函数的单调性\n",
    "# NLLLoss:计算损失，此过程不需要手动one-hot编码，NLLLoss会自动完成\n",
    "\n",
    "# SGD，优化器，梯度下降算法e\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.14)#lr:学习率\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train():\n",
    "    # index = 0\n",
    "    for index, data in enumerate(train_loader):#获取训练数据以及对应标签\n",
    "        # for data in train_loader:\n",
    "       input, target = data   # input为输入数据，target为标签\n",
    "       input, target = input.to(device), target.to(device)\n",
    "       y_predict = model(input) #模型预测\n",
    "       loss = criterion(y_predict, target)\n",
    "       optimizer.zero_grad() #梯度清零\n",
    "       loss.backward()#loss值反向传播\n",
    "       optimizer.step()#更新参数\n",
    "       # index += 1\n",
    "       if index % 100 == 0: # 每一百次保存一次模型，打印损失\n",
    "           torch.save(model.state_dict(), \"./mnist/model.pkl\")   # 保存模型\n",
    "           torch.save(optimizer.state_dict(), \"./mnist/optimizer.pkl\")\n",
    "           print(\"训练次数为：{}，损失值为：{}\".format(index, loss.item() ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "if os.path.exists('./mnist/model.pkl'):\n",
    "   model.load_state_dict(torch.load(\"./mnist/model.pkl\"))#加载保存模型的参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "def test():\n",
    "    correct = 0     # 正确预测的个数\n",
    "    total = 0   # 总数\n",
    "    with torch.no_grad():   # 测试不用计算梯度\n",
    "        for data in test_loader:\n",
    "            input, target = data\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            output = model(input)   # output输出10个预测取值，概率最大的为预测数\n",
    "            probability, predict = torch.max(input=output.data, dim=1)    # 返回一个元祖，第一个为最大概率值，第二个为最大概率值的下标\n",
    "            # loss = criterion(output, target)\n",
    "            total += target.size(0)  # target是形状为（batch_size,1)的矩阵，使用size（0）取出该批的大小\n",
    "            correct += (predict == target).sum().item()  # predict 和target均为（batch_size,1)的矩阵，sum求出相等的个数\n",
    "        print(\"测试准确率为：%.6f\" %(correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_mydata():\n",
    "#     image = Image.open('./test/test_two.png')   #读取自定义手写图片\n",
    "#     image = image.resize((28, 28))   # 裁剪尺寸为28*28\n",
    "#     image = image.convert('L')  # 转换为灰度图像\n",
    "#     transform = transforms.ToTensor()\n",
    "#     image = transform(image)\n",
    "#     image = image.resize(1, 1, 28, 28)\n",
    "#     output = model(image)\n",
    "#     probability, predict = torch.max(output.data, dim=1)\n",
    "#     print(\"此手写图片值为：%d,其最大概率为：%.2f \" % (predict[0], probability))\n",
    "#     plt.title(\"此手写图片值为：{}\".format((int(predict))), fontname='SimHei')\n",
    "#     plt.imshow(image.squeeze())\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'————————第1轮测试开始——————'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aup/miniconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at ../aten/src/ATen/Context.cpp:296.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数为：0，损失值为：2.2985241413116455\n",
      "训练次数为：100，损失值为：0.3500272333621979\n",
      "训练次数为：200，损失值为：0.28681322932243347\n",
      "训练次数为：300，损失值为：0.25636929273605347\n",
      "训练次数为：400，损失值为：0.1662430316209793\n",
      "训练次数为：500，损失值为：0.21189576387405396\n",
      "训练次数为：600，损失值为：0.12951938807964325\n",
      "训练次数为：700，损失值为：0.04319903627038002\n",
      "训练次数为：800，损失值为：0.013889332301914692\n",
      "训练次数为：900，损失值为：0.020000165328383446\n",
      "测试准确率为：0.949400\n",
      "{'————————第2轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.33590424060821533\n",
      "训练次数为：100，损失值为：0.00954714696854353\n",
      "训练次数为：200，损失值为：0.029926354065537453\n",
      "训练次数为：300，损失值为：0.05981560796499252\n",
      "训练次数为：400，损失值为：0.03144581988453865\n",
      "训练次数为：500，损失值为：0.033553045243024826\n",
      "训练次数为：600，损失值为：0.061751674860715866\n",
      "训练次数为：700，损失值为：0.01230060588568449\n",
      "训练次数为：800，损失值为：0.03933113440871239\n",
      "训练次数为：900，损失值为：0.009186455979943275\n",
      "测试准确率为：0.978200\n",
      "{'————————第3轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.11327020078897476\n",
      "训练次数为：100，损失值为：0.0027133270632475615\n",
      "训练次数为：200，损失值为：0.0312111284583807\n",
      "训练次数为：300，损失值为：0.05542729049921036\n",
      "训练次数为：400，损失值为：0.08041539788246155\n",
      "训练次数为：500，损失值为：0.03607082739472389\n",
      "训练次数为：600，损失值为：0.008256172761321068\n",
      "训练次数为：700，损失值为：0.05058712512254715\n",
      "训练次数为：800，损失值为：0.1107429787516594\n",
      "训练次数为：900，损失值为：0.02995290979743004\n",
      "测试准确率为：0.979200\n",
      "{'————————第4轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.17829853296279907\n",
      "训练次数为：100，损失值为：0.013341129757463932\n",
      "训练次数为：200，损失值为：0.026982782408595085\n",
      "训练次数为：300，损失值为：0.05616462975740433\n",
      "训练次数为：400，损失值为：0.030744044110178947\n",
      "训练次数为：500，损失值为：0.029121985659003258\n",
      "训练次数为：600，损失值为：0.007464816328138113\n",
      "训练次数为：700，损失值为：0.004770081490278244\n",
      "训练次数为：800，损失值为：0.022228825837373734\n",
      "训练次数为：900，损失值为：0.013824030756950378\n",
      "测试准确率为：0.984800\n",
      "{'————————第5轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.007351295556873083\n",
      "训练次数为：100，损失值为：0.0013872268609702587\n",
      "训练次数为：200，损失值为：0.16167226433753967\n",
      "训练次数为：300，损失值为：0.03265601769089699\n",
      "训练次数为：400，损失值为：0.01898580975830555\n",
      "训练次数为：500，损失值为：0.0897904708981514\n",
      "训练次数为：600，损失值为：0.0017271690303459764\n",
      "训练次数为：700，损失值为：0.027004674077033997\n",
      "训练次数为：800，损失值为：0.07053399831056595\n",
      "训练次数为：900，损失值为：0.0013465039664879441\n",
      "测试准确率为：0.987200\n",
      "{'————————第6轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.02752358466386795\n",
      "训练次数为：100，损失值为：0.004913016222417355\n",
      "训练次数为：200，损失值为：0.15932857990264893\n",
      "训练次数为：300，损失值为：0.00996055081486702\n",
      "训练次数为：400，损失值为：0.021950343623757362\n",
      "训练次数为：500，损失值为：0.0062173521146178246\n",
      "训练次数为：600，损失值为：0.05213948339223862\n",
      "训练次数为：700，损失值为：0.016334855929017067\n",
      "训练次数为：800，损失值为：0.06669338047504425\n",
      "训练次数为：900，损失值为：0.04467034339904785\n",
      "测试准确率为：0.988900\n",
      "{'————————第7轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.11238633096218109\n",
      "训练次数为：100，损失值为：0.0378684364259243\n",
      "训练次数为：200，损失值为：0.045834098011255264\n",
      "训练次数为：300，损失值为：0.011477936059236526\n",
      "训练次数为：400，损失值为：0.0002634711272548884\n",
      "训练次数为：500，损失值为：0.03710728883743286\n",
      "训练次数为：600，损失值为：0.027721041813492775\n",
      "训练次数为：700，损失值为：0.031673308461904526\n",
      "训练次数为：800，损失值为：0.014134279452264309\n",
      "训练次数为：900，损失值为：0.04375401511788368\n",
      "测试准确率为：0.990000\n",
      "{'————————第8轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.022861119359731674\n",
      "训练次数为：100，损失值为：0.09449514001607895\n",
      "训练次数为：200，损失值为：0.0007211680058389902\n",
      "训练次数为：300，损失值为：0.003607683116570115\n",
      "训练次数为：400，损失值为：0.013389794155955315\n",
      "训练次数为：500，损失值为：0.0023116893135011196\n",
      "训练次数为：600，损失值为：0.02621598169207573\n",
      "训练次数为：700，损失值为：0.010928736999630928\n",
      "训练次数为：800，损失值为：0.01886322908103466\n",
      "训练次数为：900，损失值为：0.0127315828576684\n",
      "测试准确率为：0.989100\n",
      "{'————————第9轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.012519204057753086\n",
      "训练次数为：100，损失值为：0.009556928649544716\n",
      "训练次数为：200，损失值为：0.0346892774105072\n",
      "训练次数为：300，损失值为：0.005011693574488163\n",
      "训练次数为：400，损失值为：0.006307733245193958\n",
      "训练次数为：500，损失值为：0.053158726543188095\n",
      "训练次数为：600，损失值为：0.0010403578635305166\n",
      "训练次数为：700，损失值为：0.040669262409210205\n",
      "训练次数为：800，损失值为：0.06556199491024017\n",
      "训练次数为：900，损失值为：0.07186012715101242\n",
      "测试准确率为：0.989600\n",
      "{'————————第10轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.010461116209626198\n",
      "训练次数为：100，损失值为：0.0006973628187552094\n",
      "训练次数为：200，损失值为：0.06617466360330582\n",
      "训练次数为：300，损失值为：0.011118206195533276\n",
      "训练次数为：400，损失值为：0.13079284131526947\n",
      "训练次数为：500，损失值为：0.00011143473966512829\n",
      "训练次数为：600，损失值为：0.03114204667508602\n",
      "训练次数为：700，损失值为：0.002909849863499403\n",
      "训练次数为：800，损失值为：0.026415012776851654\n",
      "训练次数为：900，损失值为：0.03224031627178192\n",
      "测试准确率为：0.990000\n",
      "{'————————第11轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.011339390650391579\n",
      "训练次数为：100，损失值为：0.00794883444905281\n",
      "训练次数为：200，损失值为：0.0014857550850138068\n",
      "训练次数为：300，损失值为：0.015804296359419823\n",
      "训练次数为：400，损失值为：0.004939537961035967\n",
      "训练次数为：500，损失值为：0.016456475481390953\n",
      "训练次数为：600，损失值为：0.0007492071599699557\n",
      "训练次数为：700，损失值为：0.00028666199068538845\n",
      "训练次数为：800，损失值为：0.11635076999664307\n",
      "训练次数为：900，损失值为：0.012850056402385235\n",
      "测试准确率为：0.963400\n",
      "{'————————第12轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.01176247838884592\n",
      "训练次数为：100，损失值为：7.075441681081429e-05\n",
      "训练次数为：200，损失值为：0.000373911956558004\n",
      "训练次数为：300，损失值为：0.022724008187651634\n",
      "训练次数为：400，损失值为：0.0111567173153162\n",
      "训练次数为：500，损失值为：0.013800549320876598\n",
      "训练次数为：600，损失值为：8.310299745062366e-05\n",
      "训练次数为：700，损失值为：0.10631603002548218\n",
      "训练次数为：800，损失值为：0.006116311065852642\n",
      "训练次数为：900，损失值为：0.005599568132311106\n",
      "测试准确率为：0.986500\n",
      "{'————————第13轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.011212529614567757\n",
      "训练次数为：100，损失值为：0.007818548940122128\n",
      "训练次数为：200，损失值为：0.1161598339676857\n",
      "训练次数为：300，损失值为：0.02778334729373455\n",
      "训练次数为：400，损失值为：0.0016867398517206311\n",
      "训练次数为：500，损失值为：0.018593281507492065\n",
      "训练次数为：600，损失值为：0.045006513595581055\n",
      "训练次数为：700，损失值为：0.014162309467792511\n",
      "训练次数为：800，损失值为：0.004969796631485224\n",
      "训练次数为：900，损失值为：0.0014049706514924765\n",
      "测试准确率为：0.988900\n",
      "{'————————第14轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.0009393412619829178\n",
      "训练次数为：100，损失值为：0.004066826775670052\n",
      "训练次数为：200，损失值为：0.03353580832481384\n",
      "训练次数为：300，损失值为：0.012301880866289139\n",
      "训练次数为：400，损失值为：0.009902900084853172\n",
      "训练次数为：500，损失值为：0.0004660921113099903\n",
      "训练次数为：600，损失值为：0.00033067207550629973\n",
      "训练次数为：700，损失值为：0.00040851772064343095\n",
      "训练次数为：800，损失值为：0.00034522608621045947\n",
      "训练次数为：900，损失值为：0.00466834707185626\n",
      "测试准确率为：0.989600\n",
      "{'————————第15轮测试开始——————'}\n",
      "训练次数为：0，损失值为：0.001810033223591745\n",
      "训练次数为：100，损失值为：0.0014822558732703328\n",
      "训练次数为：200，损失值为：0.0009225750691257417\n",
      "训练次数为：300，损失值为：0.03492921218276024\n",
      "训练次数为：400，损失值为：0.007834447547793388\n",
      "训练次数为：500，损失值为：0.08094097673892975\n",
      "训练次数为：600，损失值为：0.0044158510863780975\n",
      "训练次数为：700，损失值为：0.06566312164068222\n",
      "训练次数为：800，损失值为：0.014231921173632145\n",
      "训练次数为：900，损失值为：0.0004912381991744041\n",
      "测试准确率为：0.990700\n"
     ]
    }
   ],
   "source": [
    "#测试识别函数\n",
    "if __name__ == '__main__':\n",
    "    #训练与测试\n",
    "    for i in range(15):#训练和测试进行15轮\n",
    "        print({\"————————第{}轮测试开始——————\".format (i + 1)})\n",
    "        train()\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
